# OCR Skill 部署说明

> 让无视觉能力的大模型（如 GLM-4.7）也能"看"图片

## 背景问题

OpenWork 中的部分大模型（如智谱 GLM-4.7）本身无法识别图片。即使使用现有的 pdf/pptx skills，这些模型也看不到图像内容。

**解决方案**：部署本地 OCR 模型，先提取图片中的文字，再传给主模型分析。

---

## 技术选型

### 为什么选择 DeepSeek-OCR？

| 特性 | 说明 |
|------|------|
| **引擎** | DeepSeek-OCR 3B (VLM) |
| **OCRBench** | 834 分（超越 GPT-4o 的 736） |
| **压缩率** | 10x 压缩保持 97% 精度 |
| **语言支持** | 100+ 种语言 |
| **自定义 prompt** | ✅ 支持 |
| **运行环境** | macOS Apple Silicon 完美支持 |

### 双模式设计

| 模式 | 引擎 | 用途 | 速度 |
|------|------|------|------|
| **默认** | DeepSeek-OCR 3B | 智能提取，支持自定义 prompt | 10-30秒/图 |
| **快速** (`--fast`) | PaddleOCR PP-OCRv5 | 纯文字提取 | 1-3秒/图 |

---

## 工作原理

```
┌─────────────┐     ┌──────────────────┐     ┌─────────────────┐
│ 用户输入    │     │ DeepSeek-OCR     │     │ 主模型          │
│ (图片/PDF)  │────▶│ (本地 Ollama)    │────▶│ (GLM-4.7等)     │
│             │     │ 提取/理解内容    │     │ 分析处理        │
└─────────────┘     └──────────────────┘     └─────────────────┘
```

### 调用流程

1. 用户提供图片或 PDF 路径
2. `ocr.py` 调用 DeepSeek-OCR (通过 Ollama)
3. 对图片进行智能识别（支持自定义 prompt）
4. 返回提取的文本或分析结果
5. 将结果传给主模型进行进一步分析

---

## 完整复现步骤

### 前置条件

- macOS (Apple Silicon 或 Intel)
- Python 3.8+
- Homebrew

### 第一步：安装 Ollama

```bash
brew install ollama
brew services start ollama
```

### 第二步：下载 DeepSeek-OCR 模型

```bash
ollama pull deepseek-ocr
```

> 模型大小约 6.7GB，下载需要几分钟

### 第三步：安装 Python 依赖

```bash
# 核心依赖
pip install requests

# PDF 支持
pip install pdf2image
brew install poppler

# (可选) 快速模式
pip install paddleocr paddlepaddle
```

### 第四步：创建 Skill 目录

```bash
# OpenWork 的 Skills 目录位置
SKILLS_DIR=~/Library/Application\ Support/com.differentai.openwork/workspaces/starter/.opencode/skills

# 从 GitHub 克隆
cd "$SKILLS_DIR"
git clone https://github.com/mr-shaper/opencode-skills-paddle-ocr.git paddle-ocr
```

### 第五步：验证安装

```bash
cd "$SKILLS_DIR/paddle-ocr"
python3 scripts/setup_check.py
```

### 第六步：测试 OCR

```bash
# 默认模式 (DeepSeek-OCR)
python3 scripts/ocr.py 测试图片.png

# 自定义 prompt
python3 scripts/ocr.py 表格.png --prompt "提取表格为 markdown 格式"

# 快速模式 (PaddleOCR)
python3 scripts/ocr.py 测试图片.png --fast
```

---

## 目录结构说明

### OpenWork Skills 正确位置

```
~/Library/Application Support/com.differentai.openwork/
└── workspaces/
    └── starter/
        └── .opencode/
            └── skills/           ← 所有 Skills 在这里
                ├── paddle-ocr/   ← OCR Skill
                ├── pdf/
                ├── pptx/
                └── ...
```

### Skill 文件结构

```
paddle-ocr/
├── SKILL.md              # Skill 主文档
├── README.md             # GitHub 说明
├── 部署说明.md            # 本文档
├── .gitignore
├── .env.example
└── scripts/
    ├── ocr.py            # 核心 OCR 脚本 (双模式)
    ├── setup_check.py    # 环境检查
    └── requirements.txt  # Python 依赖
```

---

## 使用示例

### 基础用法

```bash
cd paddle-ocr

# 默认模式 (DeepSeek-OCR，智能理解)
python3 scripts/ocr.py image.png

# 快速模式 (PaddleOCR，纯文字)
python3 scripts/ocr.py image.png --fast

# 自定义 prompt
python3 scripts/ocr.py table.png --prompt "提取表格为 markdown"
python3 scripts/ocr.py chart.png --prompt "图表中的数据是什么？"

# PDF OCR
python3 scripts/ocr.py document.pdf

# 输出为 JSON
python3 scripts/ocr.py image.png --json > result.json

# 保存到文件
python3 scripts/ocr.py doc.pdf --output extracted.txt
```

### 在代码中集成

```python
import subprocess
import json

# 调用 OCR（支持自定义 prompt）
result = subprocess.run(
    ["python3", "scripts/ocr.py", "chart.png", "--json",
     "--prompt", "提取图表中的所有数据点"],
    capture_output=True, text=True,
    cwd="/path/to/paddle-ocr"
)

# 解析结果
ocr_data = json.loads(result.stdout)
extracted_text = ocr_data["text"]

# 构建增强提示词，传给主模型
prompt = f"""
以下是从图片中提取的内容：

{extracted_text}

请分析这些数据并给出见解。
"""
```

---

## 资源占用分析

### 模型文件

| 组件 | 大小 | 位置 |
|------|------|------|
| DeepSeek-OCR 3B | 6.7 GB | `~/.ollama/models/` |
| PaddleOCR (可选) | ~200 MB | `~/.paddlex/official_models/` |

### 运行时资源

| 状态 | Ollama | DeepSeek-OCR | 说明 |
|------|--------|--------------|------|
| **空闲时** | ~30MB | 未加载 | Ollama 常驻但不占用 GPU |
| **首次调用** | ~30MB | 加载中 | 加载模型到内存 |
| **推理时** | ~30MB | ~6-8GB | 处理图片时 |
| **推理完成** | ~30MB | 保持加载 | 模型留在内存，下次调用更快 |

### 性能预期 (Apple Silicon Mac)

| 场景 | DeepSeek-OCR | PaddleOCR (--fast) |
|------|--------------|-------------------|
| 首次运行（加载模型） | 10-20 秒 | 3-5 秒 |
| 简单文本图片 | 10-15 秒 | 1-3 秒 |
| 复杂表格图片 | 15-30 秒 | 3-8 秒 |
| 单页 PDF | 15-30 秒 | 5-10 秒 |
| 10 页 PDF | 3-5 分钟 | 1-2 分钟 |

---

## Ollama 服务管理

```bash
# 查看服务状态
brew services list | grep ollama

# 启动服务
brew services start ollama

# 停止服务（释放内存）
brew services stop ollama

# 重启服务
brew services restart ollama

# 查看已加载模型
ollama ps

# 卸载模型（释放内存但保留模型文件）
ollama stop deepseek-ocr

# 删除模型（完全移除）
ollama rm deepseek-ocr
```

---

## 常见问题

### Q: Ollama 无法连接？

```bash
# 确保 Ollama 服务已启动
brew services start ollama

# 检查服务状态
brew services list | grep ollama
```

### Q: DeepSeek-OCR 模型未找到？

```bash
# 下载模型
ollama pull deepseek-ocr

# 检查已安装模型
ollama list
```

### Q: PDF 处理失败？

```bash
# 确保 poppler 已安装
brew install poppler

# 确保 pdf2image 已安装
pip install pdf2image
```

### Q: 内存占用太高？

```bash
# 停止 Ollama 服务（完全释放）
brew services stop ollama

# 或只卸载模型（保持服务运行）
ollama stop deepseek-ocr
```

### Q: 快速模式不可用？

```bash
# 安装 PaddleOCR
pip install paddleocr paddlepaddle
```

---

## 模型对比

| 对比项 | DeepSeek-OCR 3B | PaddleOCR PP-OCRv5 |
|--------|-----------------|-------------------|
| 类型 | VLM (视觉语言模型) | 传统 OCR 流水线 |
| 大小 | 6.7 GB | ~200 MB |
| 架构 | Transformer + Vision | Detection + Recognition |
| 自定义 prompt | ✅ 支持 | ❌ 不支持 |
| OCRBench | 834 (超 GPT-4o) | - |
| 速度 | 10-30秒/图 | 1-3秒/图 |
| 最适合 | 理解图像内容 | 纯文字提取 |

---

## 相关资源

- [DeepSeek-OCR GitHub](https://github.com/deepseek-ai/DeepSeek-OCR)
- [DeepSeek-OCR HuggingFace](https://huggingface.co/deepseek-ai/DeepSeek-OCR)
- [PaddleOCR GitHub](https://github.com/PaddlePaddle/PaddleOCR)
- [Ollama](https://ollama.ai)
- [本项目 GitHub](https://github.com/mr-shaper/opencode-skills-paddle-ocr)

---

*最后更新: 2026-02-03*
